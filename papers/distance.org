* Learning Program Distance Metrics

Our goal is to choose a syntactic notion of closeness that allows us to learn a
similar closeness relation on the semantics of our programs. We would like these
two relations to be related to each other so that close values can be produced
by programs that are close.  We know that this problem is difficult in general,
but we hope that it is more tractable when considering a single synthesis
instance.

** What is syntactic closeness?

Let $P$ be a term in some DSL. We consider terms of the form $T ::= f(T_1,
\dots, T_n) ~|~ c$ where $f \in Op$ and $c \in Const$. The sets $Op$ and $Const$
are determined by the choice of DSL.

The syntactic closeness relation needs to respect some syntax
properties. I.e. if $t$ is close to $t'$ then $f(t)$ should be fairly close to
$f(t')$.

** Will any kind of "syntactic closeness" work?

There are lots of natural ways to think about the syntactic distance between
programs (diffs, tree edit distance, etc.). Can we choose any of these, collect
sets of close programs, evaluate them, and learn a semantic closeness relation
that way? The answer seems to be no.

We'll consider the tree edit distance, but other kinds of syntactic distance
should behave similarly. Two terms $t, t'$ have a tree edit distance of $\delta$
if the shortest sequence of tree edits that transforms $t$ into $t'$ has length
$\delta$. We consider tree edits that use the following operations: rename,
insert, delete. Computing the tree edit distance between terms is inexpensive,
but all we really need to do is enumerate or sample terms within a given
distance from a center. We can do this by sampling or enumerating edit sequences
of a given length.

*** Empirical evaluation

We sample a set of 50 programs from our CAD DSL. We sample programs at random
and only consider programs with 8 operators. These programs will form the center
of our classes. For each sample $t_c$, we collect a neighborhood of 500 programs
within 2 edits of $t_c$. We ensure that every program in the ball has at least 8
operators (since the rewrites can remove operators). We treat each ball as a
separate class and attempt to learn a k-nearest-neighbors classifier. The
resulting classifier has a test accuracy of 0.226 (a random classifier would
have an accuracy of 0.02).

This might sound ok, because we haven't learned a distance function yet. We're
using the Euclidean distance in the KNN classifier, and we know that the
Euclidean distance doesn't work that well for our domain. However, if we look at
the overlap between classes, we can see that there is no distance metric that
will allow us to separate the classes effectively. This plot shows the pairwise
class overlap. Brighter colors mean more values are present in multiple
classes. The neighborhoods that we have collected have large areas of overlap.


#+DOWNLOADED: screenshot @ 2021-07-22 12:21:39
[[file:Learning_Program_Distance_Metrics/2021-07-22_12-21-39_screenshot.png]]

** A hypothesis about program space

It seems clear that we need to reconsider our notion of syntactic closeness. At
the very least, we need to produce neighborhoods that 

There are a few possibilities that we should consider at this point.

1. Maybe small changes in the text of the program cause large and unpredictable
   changes in the program's behavior. This is unintuitive in the CAD domain, but
   plausible in other domains, such as cryptographic functions. This also
   doesn't explain why there is so much overlap between the neighborhoods. If
   changing the program text caused a random change to the program's output,
   then we wouldn't expect many of those changes to collide.
2. Maybe there aren't very many possible program outputs in our DSL, so every
   program is effectively close. Again, this might be true for some DSLs, but
   our CAD programs produce 30x30 pixel images for $2^{900}$ possible outputs. Not
   all of these outputs are reachable of course, but we can reach a large space.
3. Maybe there are some values that are "attractive." Making small changes to a
   program is more likely to produce one of these attractive values, and it's
   these values that make up the overlap.

I think that the third hypothesis is the correct one. Let $C(v)$ be the size of
the smallest program that produces a value $v$. If we filter our neighborhoods
to only contain values $v$ such that $C(v) \geq C(v_{center})$, we find that
most of the overlap disappears.


#+DOWNLOADED: screenshot @ 2021-07-22 12:21:49
[[file:Learning_Program_Distance_Metrics/2021-07-22_12-21-49_screenshot.png]]

If we train a classifier on this filtered dataset we get an improved accuracy of
0.465.

The values in our neighborhood are upper bounded by $C(v_{center}) + \delta$, so
we won't see arbitrarily large values of $C$. However, it seems that making
arbitrary syntactic changes is very likely to reduce $C$. We find that about
half of the neighborhood has $C < C(v_{center})$. This is a little surprising,
since there are fewer $v$ with $C(v) = k$ than $C(v) = k + 1$.

** Implementation

Obviously $C(v)$ is expensive to compute. We would need to approximate it if we
want to use it as part of neighborhood sampling.

How do we create an approximate $\hat{C}$?

